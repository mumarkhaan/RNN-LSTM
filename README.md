# RNN-LSTM
Recurrent Neural Networks
(RNNs) are useful, but they have some big challenges, especially for language translation. While working on an English-to-Urdu translation model using RNNs, we ran into a few common issues that show where RNNs struggle. Hereâ€™s what we found.

Handling Long Sequences
RNNs have trouble with long sequences, leading to problems like exploding or vanishing gradients. During training, gradients can either get too large or too small, making it hard for the model to learn.

Poor Performance on Large Datasets with Complex Language Pairs
I faced issues regarding large dataset while training it took so much time , When dealing with large datasets and complex language pairs like English and Urdu, RNNs often fall short compared to more advanced models.

Conclusion
RNNs have been important for sequence-to-sequence tasks like translation, but they have clear limitations that make them less effective for complex tasks involving long sequences or languages with tricky grammar like Urdu.
------------------------------------------------------------------------
Better Handling of Long-Term Dependencies:
The LSTM model's architecture, with its memory cells and gating mechanisms, allowed it to effectively capture long-term dependencies within the input sequences. This resulted in a significant improvement in translation accuracy, especially for longer sentences.

Higher Efficiency:
Despite requiring more parameters than the RNN, the LSTM model trained more efficiently and reached convergence faster. The use of forget, input, and output gates helped mitigate the vanishing gradient problem, resulting in a more stable training process.

Higher BLEU Score:
The LSTM model achieved a higher average BLEU score compared to the RNN, indicating better translation quality. It was able to maintain the context of the input sentences more effectively, leading to translations that were closer to the reference sentences.

Remaining Challenges with LSTM
While the LSTM model outperformed the RNN model, there are still challenges that need to be addressed for further improvements in English-to-Urdu translation:

Handling Complex Sentence Structures: LSTMs, despite their advantages, still struggle with highly complex sentence structures. For more nuanced translations, LSTMs may fail to capture subtle language intricacies, which affects translation quality.

LSTM Model Performance and Improvements
The LSTM model, on the other hand, demonstrated superior performance in almost every aspect

Conclusion
Based on my experience and the evaluation results, it is evident that the LSTM model outperforms the RNN model for the English-to-Urdu translation task.but their is always room for improvement .
